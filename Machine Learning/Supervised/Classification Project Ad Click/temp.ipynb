{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80ad186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix,classification_report,roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score, log_loss, precision_recall_curve, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import requests\n",
    "import io\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "sns.set_theme(style=\"dark\")\n",
    "pd.set_option('display.max_columns', 0)\n",
    "plt.style.use('ggplot')\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a1e4c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Ad_Click_prediction_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "045733bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateTime'] = pd.to_datetime(df['DateTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4ca9344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 463291 entries, 0 to 463290\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count   Dtype         \n",
      "---  ------                  --------------   -----         \n",
      " 0   session_id              463291 non-null  int64         \n",
      " 1   DateTime                463291 non-null  datetime64[ns]\n",
      " 2   user_id                 463291 non-null  int64         \n",
      " 3   product                 463291 non-null  object        \n",
      " 4   campaign_id             463291 non-null  int64         \n",
      " 5   webpage_id              463291 non-null  int64         \n",
      " 6   product_category_1      463291 non-null  int64         \n",
      " 7   product_category_2      97437 non-null   float64       \n",
      " 8   user_group_id           445048 non-null  float64       \n",
      " 9   gender                  445048 non-null  object        \n",
      " 10  age_level               445048 non-null  float64       \n",
      " 11  user_depth              445048 non-null  float64       \n",
      " 12  city_development_index  338162 non-null  float64       \n",
      " 13  var_1                   463291 non-null  int64         \n",
      " 14  is_click                463291 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(5), int64(7), object(2)\n",
      "memory usage: 53.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0475301c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "4         5 days 09:08:00\n",
       "6         1 days 11:26:00\n",
       "19        2 days 14:37:00\n",
       "25        4 days 03:45:00\n",
       "26        1 days 03:59:00\n",
       "                ...      \n",
       "1141714   0 days 20:08:00\n",
       "1141716   0 days 06:02:00\n",
       "1141718   1 days 09:43:00\n",
       "1141723   2 days 05:21:00\n",
       "1141729   2 days 03:15:00\n",
       "Name: DateTime, Length: 150347, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximum = df['DateTime'].max()\n",
    "maximum - df.groupby('user_id')['DateTime'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f617094e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>webpage_id</th>\n",
       "      <th>product_category_1</th>\n",
       "      <th>product_category_2</th>\n",
       "      <th>user_group_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_level</th>\n",
       "      <th>user_depth</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>var_1</th>\n",
       "      <th>is_click</th>\n",
       "      <th>last_click_time</th>\n",
       "      <th>time_since_last_click_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291898</th>\n",
       "      <td>566299</td>\n",
       "      <td>2017-07-05 18:38:00</td>\n",
       "      <td>1141723</td>\n",
       "      <td>H</td>\n",
       "      <td>118601</td>\n",
       "      <td>28529</td>\n",
       "      <td>5</td>\n",
       "      <td>82527.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-07-05 18:33:00</td>\n",
       "      <td>300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281609</th>\n",
       "      <td>15398</td>\n",
       "      <td>2017-07-05 16:31:00</td>\n",
       "      <td>1141729</td>\n",
       "      <td>H</td>\n",
       "      <td>82320</td>\n",
       "      <td>1734</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281610</th>\n",
       "      <td>124110</td>\n",
       "      <td>2017-07-05 16:31:00</td>\n",
       "      <td>1141729</td>\n",
       "      <td>C</td>\n",
       "      <td>359520</td>\n",
       "      <td>13787</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-07-05 16:31:00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307180</th>\n",
       "      <td>22020</td>\n",
       "      <td>2017-07-05 20:44:00</td>\n",
       "      <td>1141729</td>\n",
       "      <td>C</td>\n",
       "      <td>360936</td>\n",
       "      <td>13787</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-07-05 16:31:00</td>\n",
       "      <td>15180.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307181</th>\n",
       "      <td>296274</td>\n",
       "      <td>2017-07-05 20:44:00</td>\n",
       "      <td>1141729</td>\n",
       "      <td>C</td>\n",
       "      <td>360936</td>\n",
       "      <td>13787</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-07-05 20:44:00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id  ... time_since_last_click_sec\n",
       "291898      566299  ...                    300.00\n",
       "281609       15398  ...                     -1.00\n",
       "281610      124110  ...                      0.00\n",
       "307180       22020  ...                  15180.00\n",
       "307181      296274  ...                      0.00\n",
       "\n",
       "[5 rows x 17 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(['user_id', 'DateTime'])\n",
    "df['last_click_time'] = df.groupby('user_id')['DateTime'].shift(1)\n",
    "df['time_since_last_click_sec'] = (df['DateTime'] - df['last_click_time']).dt.total_seconds().fillna(-1)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95beb202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_product_count'] = df.groupby(['user_id', 'product']).cumcount()\n",
    "df['user_cat_1_count'] = df.groupby(['user_id', 'product_category_1']).cumcount()\n",
    "df['user_cat_2_count'] = df.groupby(['user_id', 'product_category_2']).cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e07f20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463291, 463291)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.session_id.nunique(),len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcb270c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>webpage_id</th>\n",
       "      <th>product_category_1</th>\n",
       "      <th>product_category_2</th>\n",
       "      <th>user_group_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_level</th>\n",
       "      <th>user_depth</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>var_1</th>\n",
       "      <th>is_click</th>\n",
       "      <th>last_click_time</th>\n",
       "      <th>time_since_last_click_sec</th>\n",
       "      <th>user_cat_count</th>\n",
       "      <th>user_product_count</th>\n",
       "      <th>user_cat_1_count</th>\n",
       "      <th>user_cat_2_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45068</th>\n",
       "      <td>4321</td>\n",
       "      <td>2017-07-02 14:51:00</td>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>404347</td>\n",
       "      <td>53587</td>\n",
       "      <td>1</td>\n",
       "      <td>146115.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347168</th>\n",
       "      <td>106452</td>\n",
       "      <td>2017-07-06 12:33:00</td>\n",
       "      <td>6</td>\n",
       "      <td>C</td>\n",
       "      <td>405490</td>\n",
       "      <td>60305</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47703</th>\n",
       "      <td>538078</td>\n",
       "      <td>2017-07-02 15:25:00</td>\n",
       "      <td>19</td>\n",
       "      <td>E</td>\n",
       "      <td>98970</td>\n",
       "      <td>6970</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250894</th>\n",
       "      <td>538079</td>\n",
       "      <td>2017-07-05 09:22:00</td>\n",
       "      <td>19</td>\n",
       "      <td>E</td>\n",
       "      <td>98970</td>\n",
       "      <td>6970</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-07-02 15:25:00</td>\n",
       "      <td>237420.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150872</th>\n",
       "      <td>354959</td>\n",
       "      <td>2017-07-03 20:14:00</td>\n",
       "      <td>25</td>\n",
       "      <td>B</td>\n",
       "      <td>360936</td>\n",
       "      <td>13787</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id            DateTime  ...  user_cat_1_count user_cat_2_count\n",
       "45068         4321 2017-07-02 14:51:00  ...                 0             0.00\n",
       "347168      106452 2017-07-06 12:33:00  ...                 0              NaN\n",
       "47703       538078 2017-07-02 15:25:00  ...                 0              NaN\n",
       "250894      538079 2017-07-05 09:22:00  ...                 1              NaN\n",
       "150872      354959 2017-07-03 20:14:00  ...                 0              NaN\n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafb5ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "def tune_lightgbm_robust(X, y):\n",
    "    \"\"\"\n",
    "    Performs Randomized Search with Stratified K-Fold CV.\n",
    "    Addresses Evaluator Q2: \"Rigorous hyperparameter tuning and cross-validation\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Define the Estimator\n",
    "    # Note: We use scale_pos_weight to handle imbalance instead of SMOTE\n",
    "    # (Typical ratio is sum(negative) / sum(positive))\n",
    "    ratio = float(np.sum(y == 0)) / np.sum(y == 1)\n",
    "    \n",
    "    lgbm = LGBMClassifier(\n",
    "        objective='binary',\n",
    "        metric='auc',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        scale_pos_weight=ratio, # Automatically handle imbalance\n",
    "        verbosity=-1\n",
    "    )\n",
    "\n",
    "    # 2. Define the Hyperparameter Search Space\n",
    "    # We search over a range of values to find the best combination\n",
    "    param_dist = {\n",
    "        'n_estimators': randint(100, 1000),      # Number of trees\n",
    "        'learning_rate': uniform(0.01, 0.2),     # Speed of learning\n",
    "        'max_depth': randint(3, 10),             # Depth of tree (prevent overfitting)\n",
    "        'num_leaves': randint(20, 100),          # Complexity of tree\n",
    "        'subsample': uniform(0.6, 0.4),          # Train on x% of rows\n",
    "        'colsample_bytree': uniform(0.6, 0.4),   # Train on x% of features\n",
    "        'reg_alpha': uniform(0, 10),             # L1 Regularization\n",
    "        'reg_lambda': uniform(0, 10)             # L2 Regularization\n",
    "    }\n",
    "\n",
    "    # 3. Setup Stratified K-Fold\n",
    "    # Splits data into 5 chunks, ensuring each chunk has the same % of clicks\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # 4. Setup RandomizedSearchCV\n",
    "    # n_iter=50 means it will try 50 different random combinations\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=lgbm,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=50,\n",
    "        scoring='roc_auc',\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # 5. Execute Tuning\n",
    "    print(\"Starting Hyperparameter Tuning... this may take a few minutes.\")\n",
    "    search.fit(X, y)\n",
    "    \n",
    "    print(f\"Best AUC Score: {search.best_score_:.4f}\")\n",
    "    print(\"Best Parameters:\")\n",
    "    print(search.best_params_)\n",
    "    \n",
    "    return search.best_estimator_\n",
    "\n",
    "# --- Usage ---\n",
    "# Assuming you have your X_train and y_train ready from the previous steps\n",
    "# best_model = tune_lightgbm_robust(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253c023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. The Generic Tuning Function\n",
    "# ---------------------------------------------------------\n",
    "def tune_model_robust(model_name, estimator, param_dist, X, y, n_iter=20):\n",
    "    \"\"\"\n",
    "    Universally tunes any model using Stratified K-Fold CV.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Stats: Tuning {model_name}...\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Stratified K-Fold for stable validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Randomized Search\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,       # Tries 'n_iter' random combinations\n",
    "        scoring='roc_auc',   # Optimize for AUC\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1            # Use all CPU cores\n",
    "    )\n",
    "\n",
    "    search.fit(X, y)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Done! Time taken: {elapsed/60:.2f} min\")\n",
    "    print(f\"Best AUC: {search.best_score_:.4f}\")\n",
    "    print(f\"Best Params: {search.best_params_}\")\n",
    "    \n",
    "    return search.best_estimator_\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Configuration: Define Models & Grids\n",
    "# ---------------------------------------------------------\n",
    "# Calculate imbalance ratio for Boosting models\n",
    "# ratio = negative / positive\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "model_configs = {\n",
    "    # --- Tree Ensembles (The most powerful for this data) ---\n",
    "    \"LightGBM\": {\n",
    "        \"model\": LGBMClassifier(objective='binary', scale_pos_weight=ratio, verbosity=-1, random_state=42),\n",
    "        \"params\": {\n",
    "            'n_estimators': randint(100, 1000),\n",
    "            'learning_rate': uniform(0.01, 0.2),\n",
    "            'max_depth': randint(3, 10),\n",
    "            'num_leaves': randint(20, 100),\n",
    "            'subsample': uniform(0.6, 0.4),\n",
    "            'colsample_bytree': uniform(0.6, 0.4),\n",
    "            'reg_alpha': uniform(0, 10),\n",
    "            'reg_lambda': uniform(0, 10)\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBClassifier(eval_metric='logloss', scale_pos_weight=ratio, use_label_encoder=False, random_state=42),\n",
    "        \"params\": {\n",
    "            'n_estimators': randint(100, 1000),\n",
    "            'learning_rate': uniform(0.01, 0.2),\n",
    "            'max_depth': randint(3, 10),\n",
    "            'subsample': uniform(0.6, 0.4),\n",
    "            'colsample_bytree': uniform(0.6, 0.4),\n",
    "            'gamma': uniform(0, 5)\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "        \"params\": {\n",
    "            'n_estimators': randint(100, 500),\n",
    "            'max_depth': randint(5, 20),\n",
    "            'min_samples_split': randint(2, 20),\n",
    "            'min_samples_leaf': randint(1, 10),\n",
    "            'max_features': ['sqrt', 'log2']\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # --- Linear Models ---\n",
    "    \"LogisticRegression\": {\n",
    "        \"model\": LogisticRegression(class_weight='balanced', solver='saga', max_iter=500, random_state=42),\n",
    "        \"params\": {\n",
    "            'C': loguniform(1e-4, 10),  # Log-uniform searches 0.0001 to 10 efficiently\n",
    "            'penalty': ['l1', 'l2']\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # --- Simple Trees ---\n",
    "    \"DecisionTree\": {\n",
    "        \"model\": DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "        \"params\": {\n",
    "            'max_depth': randint(3, 20),\n",
    "            'min_samples_split': randint(2, 20),\n",
    "            'min_samples_leaf': randint(1, 20),\n",
    "            'criterion': ['gini', 'entropy']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # --- Others (Warning: KNN/SVC can be very slow on large data) ---\n",
    "    \"AdaBoost\": {\n",
    "        \"model\": AdaBoostClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            'n_estimators': randint(50, 500),\n",
    "            'learning_rate': uniform(0.01, 1.0)\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff1279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_comprehensive_tuning(df_label_encoded, df_one_hot_scaled, target_col):\n",
    "    \"\"\"\n",
    "    Handles different X_train/X_val for different model types.\n",
    "    df_label_encoded: The dataframe processed for Tree models.\n",
    "    df_one_hot_scaled: The dataframe processed for Linear models.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Define Target\n",
    "    y = df_label_encoded[target_col] \n",
    "    \n",
    "    # 1. Define Model Groups\n",
    "    tree_models = ['LightGBM', 'XGBoost', 'RandomForest']\n",
    "    linear_models = ['LogisticRegression'] # Add KNN here if needed\n",
    "    # Select which models to run (You can comment out slow ones like SVC)\n",
    "    models_to_run = ['LightGBM', 'XGBoost', 'RandomForest', 'LogisticRegression']\n",
    "    \n",
    "    # 2. Iterate through the configurations\n",
    "    for name in model_configs.keys():\n",
    "        # Skip if not in our execution list\n",
    "        if name not in models_to_run:\n",
    "            continue\n",
    "            \n",
    "        # Select the correct data source\n",
    "        if name in tree_models:\n",
    "            X = df_label_encoded.drop(columns=[target_col])\n",
    "            print(f\"\\n>>> Using Label-Encoded data for {name}\")\n",
    "        elif name in linear_models:\n",
    "            X = df_one_hot_scaled.drop(columns=[target_col])\n",
    "            print(f\"\\n>>> Using One-Hot Scaled data for {name}\")\n",
    "        else:\n",
    "            X = df_label_encoded.drop(columns=[target_col])\n",
    "            \n",
    "        # Call the tuning engine (from our previous step)\n",
    "        config = model_configs[name]\n",
    "        best_model = tune_model_robust(\n",
    "            model_name=name,\n",
    "            estimator=config[\"model\"],\n",
    "            param_dist=config[\"params\"],\n",
    "            X=X,\n",
    "            y=y,\n",
    "            n_iter=15 \n",
    "        )\n",
    "        \n",
    "        results[name] = best_model\n",
    "        \n",
    "    return results\n",
    "\n",
    "# --- Usage ---\n",
    "# tuned_models = run_comprehensive_tuning(df_trees, df_linear, 'is_click')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
