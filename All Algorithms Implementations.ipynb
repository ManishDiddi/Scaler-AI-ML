{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fb1d1a2",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ac77c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e61eb70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    def __init__(self,learning_rate=0.01,epochs=100,reg=0.0):\n",
    "        self.lr = learning_rate\n",
    "        self.iters =epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.reg = reg\n",
    "\n",
    "    def predict(self,X):\n",
    "        return X.dot(self.weights) + self.bias\n",
    "\n",
    "    def _update_weights(self,X,y):\n",
    "        m = X.shape[0]\n",
    "        y_pred = self.predict(X)\n",
    "        error = y - y_pred\n",
    "        dw = -(2*X.T.dot(error))/m\n",
    "        reg = 2*(self.reg/m)*self.weights\n",
    "        dw += reg\n",
    "        db = -(2*np.sum(error))/m\n",
    "        self.weights = self.weights - self.lr*dw\n",
    "        self.bias = self.bias - self.lr*db\n",
    "        return self\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        _ , n = X.shape\n",
    "        X = np.array(X)\n",
    "        y = np.array(y).reshape(-1)\n",
    "        self.weights = np.zeros(n)\n",
    "        self.bias = 0\n",
    "        self.error_list = []\n",
    "\n",
    "        for _ in range(self.iters):\n",
    "            self._update_weights(X,y)\n",
    "            self.error_list.append(self.mse(X,y))\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def r2_score(self,X,y):\n",
    "        y = np.array(y).reshape(-1)\n",
    "        y_pred = self.predict(X)\n",
    "        ss_res = np.sum((y-y_pred)**2)\n",
    "        ss_tot = np.sum((y-y.mean())**2)\n",
    "        return 1 - ss_res/ss_tot\n",
    "\n",
    "    def mse(self,X,y):\n",
    "        m = X.shape[0]\n",
    "        y = np.array(y).reshape(-1)\n",
    "        y_pred = self.predict(X)\n",
    "        return np.sum((y-y_pred)**2)/m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d4f64ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters (true weights/biases for testing)\n",
    "true_w = np.array([2.0, -1.5])  # 2 features\n",
    "true_b = 0.5\n",
    "n_samples = 1000\n",
    "noise_scale = 0.01\n",
    "\n",
    "# Generate features (n_samples x n_features)\n",
    "X = np.random.randn(n_samples, len(true_w))\n",
    "\n",
    "# Generate targets: y = X@w + b + noise\n",
    "noise = np.random.randn(n_samples, 1) * noise_scale\n",
    "y = X @ true_w.reshape(-1, 1) + true_b + noise\n",
    "\n",
    "# Train/test split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "42450823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegression at 0x17f0fb410>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression(epochs=300,learning_rate=0.1,reg=0.1)\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "062390ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999871221438803"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "lr.r2_score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7324641f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(lr.mse(X_test,y_test),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "48c476e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.99983506, -1.49987469]), 0.5001338823209551)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.weights,lr.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2480cf3",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "30dff39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self,learning_rate=0.01,epochs=100,reg=0.0):\n",
    "        self.lr = learning_rate\n",
    "        self.iters =epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.reg = reg\n",
    "\n",
    "    def predict(self,X,threshold=0.5):\n",
    "        z = X.dot(self.weights) + self.bias\n",
    "        y_predicited = self._sigmoid(z)\n",
    "\n",
    "        return (y_predicited > threshold).astype(int)\n",
    "\n",
    "    def predict_proba(self,X):\n",
    "        return self._sigmoid(X.dot(self.weights)+self.bias)\n",
    "\n",
    "    def _update_weights(self,X,y):\n",
    "        m = X.shape[0]\n",
    "        z = np.dot(X,self.weights) + self.bias\n",
    "        y_pred = self._sigmoid(z)\n",
    "        dw = np.dot(X.T,(y_pred-y))/m\n",
    "        reg = 2*(self.reg/m)*self.weights\n",
    "        dw += reg\n",
    "        db = np.sum(y_pred-y)/m\n",
    "        self.weights = self.weights - self.lr*dw\n",
    "        self.bias = self.bias - self.lr*db\n",
    "        return self\n",
    "    \n",
    "    def _sigmoid(self,z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        _ , n = X.shape\n",
    "        X = np.array(X)\n",
    "        y = np.array(y).reshape(-1)\n",
    "        self.weights = np.zeros(n)\n",
    "        self.bias = 0\n",
    "        self.error_list = []\n",
    "\n",
    "        for _ in range(self.iters):\n",
    "            self._update_weights(X,y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def accuracy(self,X,y):\n",
    "        y = np.array(y).reshape(-1)\n",
    "        y_pred = self.predict(X)\n",
    "        return np.mean(y_pred==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0a5c91b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (800, 2)\n",
      "y_train shape: (800,)\n",
      "Class balance train: [355 445]\n"
     ]
    }
   ],
   "source": [
    "# Model parameters (true weights/biases)\n",
    "true_w = np.array([2.0, -1.5])  # 2 features\n",
    "true_b = 0.5\n",
    "n_samples = 1000\n",
    "noise_scale = 0.2\n",
    "\n",
    "# Generate features (n_samples x n_features)\n",
    "X = np.random.randn(n_samples, len(true_w))\n",
    "\n",
    "# Generate logits: z = X@w + b\n",
    "z = X @ true_w + true_b\n",
    "\n",
    "# Apply sigmoid to get probabilities\n",
    "probs = 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Sample binary labels (Bernoulli with p=probs) + noise\n",
    "y = np.random.binomial(1, probs, n_samples)\n",
    "\n",
    "# Train/test split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"Class balance train: {np.bincount(y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "48531fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x17f0fb590>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(epochs=200,learning_rate=0.2)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "152a4ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "aae5c578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83        89\n",
      "           1       0.87      0.86      0.86       111\n",
      "\n",
      "    accuracy                           0.85       200\n",
      "   macro avg       0.85      0.85      0.85       200\n",
      "weighted avg       0.85      0.85      0.85       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "03cb93bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.77524599, -1.3094776 ]), 0.37508544126101717)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights,model.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfea2c27",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "397418ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestClassifier():\n",
    "    def __init__(self,n_nearest=5):\n",
    "        self.k=n_nearest\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        self.X = np.asarray(X,dtype=float)\n",
    "        self.y = np.asarray(y,dtype=float).reshape(-1)\n",
    "\n",
    "    def predict(self,Xqs):\n",
    "        prediction=[]\n",
    "        for xq in Xqs:\n",
    "            prediction.append(self._predict_one_query_point(xq))\n",
    "        return np.array(prediction)\n",
    "\n",
    "    def _predict_one_query_point(self,xq):\n",
    "        distance = np.sqrt(np.sum((self.X - xq)**2,axis=1))\n",
    "        distance = np.array([[distance[i],self.y[i]] for i in range(len(distance))])\n",
    "        distance = distance[np.argsort(distance[:,0])]\n",
    "        distance = distance[:self.k]\n",
    "        classes,counts = np.unique(distance[:,1],return_counts=True)\n",
    "        return int(classes[counts.argmax()])\n",
    "\n",
    "    def accuracy(self,X,y):\n",
    "        y_pred = self.predict(X)\n",
    "        return np.mean(y_pred==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d8cfabb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNearestClassifier(n_nearest=5)\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cb574c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78        89\n",
      "           1       0.82      0.85      0.83       111\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.81      0.81      0.81       200\n",
      "weighted avg       0.81      0.81      0.81       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970cf6af",
   "metadata": {},
   "source": [
    "### Weighted KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "39e0284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestClassifier():\n",
    "    def __init__(self,n_nearest=5,weights=None):\n",
    "        self.k=n_nearest\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        self.X = np.asarray(X,dtype=float)\n",
    "        self.y = np.asarray(y,dtype=float).reshape(-1)\n",
    "\n",
    "    def predict(self,Xqs):\n",
    "        prediction=[]\n",
    "        for xq in Xqs:\n",
    "            prediction.append(self._predict_one_query_point(xq))\n",
    "        return np.array(prediction)\n",
    "\n",
    "    def _predict_one_query_point(self,xq):\n",
    "        distance = np.sqrt(np.sum((self.X - xq)**2,axis=1))\n",
    "        distance = np.array([[distance[i],self.y[i]] for i in range(len(distance))])\n",
    "        distance = distance[np.argsort(distance[:,0])]\n",
    "        k_nearest = distance[:self.k]\n",
    "        if self.weights == None:\n",
    "            classes,counts = np.unique(k_nearest[:,1],return_counts=True)\n",
    "            return int(classes[counts.argmax()])\n",
    "        else:\n",
    "            epsilon = 1e-4\n",
    "            class_scores = {}\n",
    "            for dist,label in k_nearest:\n",
    "                weight = 1/(dist + epsilon)\n",
    "                if label in class_scores:\n",
    "                    class_scores[label] += weight\n",
    "                else:\n",
    "                    class_scores[label] = weight\n",
    "            return int(max(class_scores,key=class_scores.get))\n",
    "            \n",
    "\n",
    "    def accuracy(self,X,y):\n",
    "        y_pred = self.predict(X)\n",
    "        return np.mean(y_pred==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ef5423be",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNearestClassifier(n_nearest=5,weights=True)\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f0075279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.77        89\n",
      "           1       0.82      0.78      0.80       111\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.78      0.79      0.78       200\n",
      "weighted avg       0.79      0.79      0.79       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fa66539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be89b41",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c137901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self,feature=None,threshold=None,value=None,left=None,right=None):\n",
    "        self.feature=feature\n",
    "        self.threshold=threshold\n",
    "        self.value=value\n",
    "        self.left=left\n",
    "        self.right=right\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06e6288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self,max_depth=10):\n",
    "        self.root=None\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def _gini_impurity(self,y):\n",
    "        return 1 - np.sum((np.bincount(y)/len(y))**2)\n",
    "\n",
    "    def _information_gain(self,parent,left_child,right_child):\n",
    "        parent_gini = self._gini_impurity(parent)\n",
    "        left_child_gini = self._gini_impurity(left_child)\n",
    "        right_child_gini = self._gini_impurity(right_child)\n",
    "        n1, n2 = len(left_child), len(right_child)\n",
    "        n = len(parent)\n",
    "        weighted_children_gini = (n1/n)*left_child_gini + (n2/n)*right_child_gini\n",
    "\n",
    "        return parent_gini - weighted_children_gini\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        print(np.unique(y))\n",
    "        self.root = self._grow_tree(X,y,0)\n",
    "    \n",
    "    def _grow_tree(self,X,y,depth):\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        if depth >= self.max_depth or n_labels == 1:\n",
    "            most_common = np.bincount(y).argmax()\n",
    "            return Node(value=most_common)\n",
    "\n",
    "        split_feature_idx, split_threshold = self._best_split(X,y)\n",
    "\n",
    "        left_child_idx = np.where(X[:,split_feature_idx] <= split_threshold)\n",
    "        left = self._grow_tree(X[left_child_idx],y[left_child_idx], depth = depth+1)\n",
    "\n",
    "        right_child_idx = np.where(X[:,split_feature_idx] > split_threshold)\n",
    "        right = self._grow_tree(X[right_child_idx],y[right_child_idx], depth = depth+1)\n",
    "\n",
    "        return Node(feature=split_feature_idx,threshold=split_threshold, left=left, right=right)\n",
    "\n",
    "    def _best_split(self,X,y):\n",
    "        n_features = X.shape[1]\n",
    "        split_threshold,best_info_gain = None, -1\n",
    "        split_feature_idx = None\n",
    "        for feature_idx in range(n_features):\n",
    "            X_column = X[:,feature_idx]\n",
    "            thresholds = np.unique(X_column)\n",
    "            for threshold in thresholds:\n",
    "                left_child_idx = np.where(X_column <= threshold) \n",
    "                right_child_idx = np.where(X_column > threshold) \n",
    "\n",
    "                info_gain = self._information_gain(y,y[left_child_idx],y[right_child_idx])\n",
    "                if info_gain > best_info_gain:\n",
    "                    best_info_gain = info_gain\n",
    "                    split_threshold = threshold\n",
    "                    split_feature_idx = feature_idx\n",
    "\n",
    "        return split_feature_idx,split_threshold\n",
    "\n",
    "    def predict(self,X):\n",
    "        return np.array([self._traverse_tree(x,self.root) for x in X])\n",
    "\n",
    "    def _traverse_tree(self,x, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "\n",
    "        split_idx = node.feature\n",
    "        split_threshold = node.threshold\n",
    "        if x[split_idx] <= split_threshold:\n",
    "            return self._traverse_tree(x,node.left)\n",
    "        else:\n",
    "            return self._traverse_tree(x,node.right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "522a1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=6,         # all numeric float features\n",
    "    n_informative=5,\n",
    "    n_redundant=1,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=1,\n",
    "    class_sep=1.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16375f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTree()\n",
    "dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea56df2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       100\n",
      "           1       0.98      0.96      0.97       100\n",
      "\n",
      "    accuracy                           0.97       200\n",
      "   macro avg       0.97      0.97      0.97       200\n",
      "weighted avg       0.97      0.97      0.97       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = dt.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
