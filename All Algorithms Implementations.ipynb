{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fb1d1a2",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac77c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e61eb70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    def __init__(self,learning_rate=0.01,epochs=100,reg=0.0):\n",
    "        self.lr = learning_rate\n",
    "        self.iters =epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.reg = reg\n",
    "\n",
    "    def predict(self,X):\n",
    "        return X.dot(self.weights) + self.bias\n",
    "\n",
    "    def _update_weights(self,X,y):\n",
    "        m = X.shape[0]\n",
    "        y_pred = self.predict(X)\n",
    "        error = y - y_pred\n",
    "        dw = -(2*X.T.dot(error))/m\n",
    "        reg = 2*(self.reg/m)*self.weights\n",
    "        dw += reg\n",
    "        db = -(2*np.sum(error))/m\n",
    "        self.weights = self.weights - self.lr*dw\n",
    "        self.bias = self.bias - self.lr*db\n",
    "        return self\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        _ , n = X.shape\n",
    "        X = np.array(X)\n",
    "        y = np.array(y).reshape(-1)\n",
    "        self.weights = np.zeros(n)\n",
    "        self.bias = 0\n",
    "        self.error_list = []\n",
    "\n",
    "        for _ in range(self.iters):\n",
    "            self._update_weights(X,y)\n",
    "            self.error_list.append(self.mse(X,y))\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def r2_score(self,X,y):\n",
    "        y = np.array(y).reshape(-1)\n",
    "        y_pred = self.predict(X)\n",
    "        ss_res = np.sum((y-y_pred)**2)\n",
    "        ss_tot = np.sum((y-y.mean())**2)\n",
    "        return 1 - ss_res/ss_tot\n",
    "\n",
    "    def mse(self,X,y):\n",
    "        m = X.shape[0]\n",
    "        y = np.array(y).reshape(-1)\n",
    "        y_pred = self.predict(X)\n",
    "        return np.sum((y-y_pred)**2)/m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4f64ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters (true weights/biases for testing)\n",
    "true_w = np.array([2.0, -1.5])  # 2 features\n",
    "true_b = 0.5\n",
    "n_samples = 1000\n",
    "noise_scale = 0.01\n",
    "\n",
    "# Generate features (n_samples x n_features)\n",
    "X = np.random.randn(n_samples, len(true_w))\n",
    "\n",
    "# Generate targets: y = X@w + b + noise\n",
    "noise = np.random.randn(n_samples, 1) * noise_scale\n",
    "y = X @ true_w.reshape(-1, 1) + true_b + noise\n",
    "\n",
    "# Train/test split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42450823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegression at 0x1643c3830>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression(epochs=300,learning_rate=0.1,reg=0.1)\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "062390ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999783995472641"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "lr.r2_score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7324641f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(lr.mse(X_test,y_test),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48c476e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.00006332, -1.49976914]), 0.5000720278378139)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.weights,lr.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2480cf3",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30dff39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self,learning_rate=0.01,epochs=100,reg=0.0):\n",
    "        self.lr = learning_rate\n",
    "        self.iters =epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.reg = reg\n",
    "\n",
    "    def predict(self,X,threshold=0.5):\n",
    "        z = X.dot(self.weights) + self.bias\n",
    "        y_predicited = self._sigmoid(z)\n",
    "\n",
    "        return (y_predicited > threshold).astype(int)\n",
    "\n",
    "    def predict_proba(self,X):\n",
    "        return self._sigmoid(X.dot(self.weights)+self.bias)\n",
    "\n",
    "    def _update_weights(self,X,y):\n",
    "        m = X.shape[0]\n",
    "        z = np.dot(X,self.weights) + self.bias\n",
    "        y_pred = self._sigmoid(z)\n",
    "        dw = np.dot(X.T,(y_pred-y))/m\n",
    "        reg = 2*(self.reg/m)*self.weights\n",
    "        dw += reg\n",
    "        db = np.sum(y_pred-y)/m\n",
    "        self.weights = self.weights - self.lr*dw\n",
    "        self.bias = self.bias - self.lr*db\n",
    "        return self\n",
    "    \n",
    "    def _sigmoid(self,z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        _ , n = X.shape\n",
    "        X = np.array(X)\n",
    "        y = np.array(y).reshape(-1)\n",
    "        self.weights = np.zeros(n)\n",
    "        self.bias = 0\n",
    "        self.error_list = []\n",
    "\n",
    "        for _ in range(self.iters):\n",
    "            self._update_weights(X,y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def accuracy(self,X,y):\n",
    "        y = np.array(y).reshape(-1)\n",
    "        y_pred = self.predict(X)\n",
    "        return np.mean(y_pred==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a5c91b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (800, 2)\n",
      "y_train shape: (800,)\n",
      "Class balance train: [331 469]\n"
     ]
    }
   ],
   "source": [
    "# Model parameters (true weights/biases)\n",
    "true_w = np.array([2.0, -1.5])  # 2 features\n",
    "true_b = 0.5\n",
    "n_samples = 1000\n",
    "noise_scale = 0.2\n",
    "\n",
    "# Generate features (n_samples x n_features)\n",
    "X = np.random.randn(n_samples, len(true_w))\n",
    "\n",
    "# Generate logits: z = X@w + b\n",
    "z = X @ true_w + true_b\n",
    "\n",
    "# Apply sigmoid to get probabilities\n",
    "probs = 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Sample binary labels (Bernoulli with p=probs) + noise\n",
    "y = np.random.binomial(1, probs, n_samples)\n",
    "\n",
    "# Train/test split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"Class balance train: {np.bincount(y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "48531fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x1643c1ca0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(epochs=200,learning_rate=0.2)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "152a4ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aae5c578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71        83\n",
      "           1       0.79      0.80      0.80       117\n",
      "\n",
      "    accuracy                           0.76       200\n",
      "   macro avg       0.75      0.75      0.75       200\n",
      "weighted avg       0.76      0.76      0.76       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "03cb93bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.97021542, -1.46754855]), 0.5768325384979366)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights,model.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfea2c27",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "397418ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestClassifier():\n",
    "    def __init__(self,n_nearest=5):\n",
    "        self.k=n_nearest\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        self.X = np.asarray(X,dtype=float)\n",
    "        self.y = np.asarray(y,dtype=float).reshape(-1)\n",
    "\n",
    "    def predict(self,Xqs):\n",
    "        prediction=[]\n",
    "        for xq in Xqs:\n",
    "            prediction.append(self._predict_one_query_point(xq))\n",
    "        return np.array(prediction)\n",
    "\n",
    "    def _predict_one_query_point(self,xq):\n",
    "        distance = np.sqrt(np.sum((self.X - xq)**2,axis=1))\n",
    "        distance = np.array([[distance[i],self.y[i]] for i in range(len(distance))])\n",
    "        distance = distance[np.argsort(distance[:,0])]\n",
    "        distance = distance[:self.k]\n",
    "        classes,counts = np.unique(distance[:,1],return_counts=True)\n",
    "        return int(classes[counts.argmax()])\n",
    "\n",
    "    def accuracy(self,X,y):\n",
    "        y_pred = self.predict(X)\n",
    "        return np.mean(y_pred==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d8cfabb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNearestClassifier(n_nearest=5)\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb574c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76        83\n",
      "           1       0.81      0.88      0.84       117\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.81      0.80      0.80       200\n",
      "weighted avg       0.81      0.81      0.81       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970cf6af",
   "metadata": {},
   "source": [
    "### Weighted KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39e0284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestClassifier():\n",
    "    def __init__(self,n_nearest=5,weights=None):\n",
    "        self.k=n_nearest\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        self.X = np.asarray(X,dtype=float)\n",
    "        self.y = np.asarray(y,dtype=float).reshape(-1)\n",
    "\n",
    "    def predict(self,Xqs):\n",
    "        prediction=[]\n",
    "        for xq in Xqs:\n",
    "            prediction.append(self._predict_one_query_point(xq))\n",
    "        return np.array(prediction)\n",
    "\n",
    "    def _predict_one_query_point(self,xq):\n",
    "        distance = np.sqrt(np.sum((self.X - xq)**2,axis=1))\n",
    "        distance = np.array([[distance[i],self.y[i]] for i in range(len(distance))])\n",
    "        distance = distance[np.argsort(distance[:,0])]\n",
    "        k_nearest = distance[:self.k]\n",
    "        if self.weights == None:\n",
    "            classes,counts = np.unique(k_nearest[:,1],return_counts=True)\n",
    "            return int(classes[counts.argmax()])\n",
    "        else:\n",
    "            epsilon = 1e-4\n",
    "            class_scores = {}\n",
    "            for dist,label in k_nearest:\n",
    "                weight = 1/(dist + epsilon)\n",
    "                if label in class_scores:\n",
    "                    class_scores[label] += weight\n",
    "                else:\n",
    "                    class_scores[label] = weight\n",
    "            return int(max(class_scores,key=class_scores.get))\n",
    "            \n",
    "\n",
    "    def accuracy(self,X,y):\n",
    "        y_pred = self.predict(X)\n",
    "        return np.mean(y_pred==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef5423be",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNearestClassifier(n_nearest=5,weights=True)\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f0075279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.75        83\n",
      "           1       0.81      0.85      0.83       117\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.79      0.78      0.79       200\n",
      "weighted avg       0.79      0.80      0.79       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
